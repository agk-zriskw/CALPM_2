---
title: "CALPM"
author: "Grupa 2"
format: 
  html:
    toc: true
    toc-location: right
    toc-title: Spis Treści
    number-sections: true
    embed-resources: true
    html-math-method: katex
    code-tools: true
    code-fold: show
    code-summary: "Show and hide code"
    link-external-icon: true
    link-external-newwindow: true
    smooth-scroll: true
    self-contained: true
    fig-align: center
execute: 
  echo: true
  cache: true
  error: false
  warning: false
  output: true
---

# Pakiety

Pakiety potrzebne do wykonanie analizy danych i modeli.

```{r}
library(tidymodels)
library(tidyverse)
library(stringr)
library(vip)
library(pdp)
library(DALEX)
library(DALEXtra)
library(bestNormalize)
library(rules)
library(baguette)
library(finetune)
library(doParallel)
library(GGally)
library(openair)
```


# Dane

Załadowanie danych treningowych.

```{r}
load("dane/ops.RData") 
```

## Opis danych znajdujących się w zbiorze

```{r}
ops |> glimpse()
```

Zestaw składa się z 21 zmiennych oraz 909 obserwacji. Objaśnienie każdej z nich:

* `date` - Data (krok 1 godzina)
* `grimm_pm10` - Średnie 1-godzinne stężenie PM10 zmierzone za pomocą GRIMM EDM 180
* `ops_pm10` - Średnie 1-godzinne stężenie PM10 zmierzone za pomocą TSI OPS 3330
* `n_0044` - liczba zliczeń cząstek w od 0.3 do 0.44 µm wyrażona w zliczeniach/cm^3^
* `n_0075` - liczba zliczeń cząstek w od 0.44 do 0.75 µm wyrażona w zliczeniach/cm^3^
* `n_0100` - liczba zliczeń cząstek w od 0.75 do 1.00 µm wyrażona w zliczeniach/cm^3^
* `n_0120` - liczba zliczeń cząstek w od 1.00 do 1.20 µm wyrażona w zliczeniach/cm^3^
* `n_0140` - liczba zliczeń cząstek w od 1.20 do 1.40 µm wyrażona w zliczeniach/cm^3^
* `n_0200` - liczba zliczeń cząstek w od 1.40 do 2.00 µm wyrażona w zliczeniach/cm^3^
* `n_0250` - liczba zliczeń cząstek w od 2.00 do 2.50 µm wyrażona w zliczeniach/cm^3^
* `n_0500` - liczba zliczeń cząstek w od 2.50 do 5.00 µm wyrażona w zliczeniach/cm^3^
* `n_0750` - liczba zliczeń cząstek w od 5.00 do 7.50 µm wyrażona w zliczeniach/cm^3^
* `n_1000` - liczba zliczeń cząstek w od 7.50 do 10.4 µm wyrażona w zliczeniach/cm^3^
* `temp` - temperatura powietrza [°C]
* `rh` - wilgotność względna [%]
* `pres` - ciśnienie na poziomie stacji [hPa]
* `pres_sea` - ciśnienie nad poziomem morza [hPa]
* `wd` - kierunek wiatru [°]
* `mws` - maksymalns prędkość wiatru [m/s]
* `ws` - prędkość wiatru [m/s]
* `prec` - opad atmosferyczny [mm/h]

```{r}
ops |> is.na() |> colSums()
```

W zbiorze można zaobserwować liczne braki danych, które należy wyeliminować przed dalszą analizą.

```{r}
ops <- ops |> 
  mutate(across(where(is.numeric), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))

ops |> is.na() |> sum()
```

Wszystkie braki danych zostały zamienione na mediane z wartości kolumny. Brak danych jakościowych umożliwia wykonanie operacji dla wszystkich atrybutów.

```{r}
ops |> summary()
```


Powyżej przedstawiono podsumowanie wszystkich atrybutów zbioru danych.

## Zbiór weryfikacyjny i przygotowanie danych do analizy

Dane w zbiorze weryfikacyjnym zawierają analogiczne informacje w stosunku do zestawu danych `ops`, ale pomiary zostały wykonane w innym czasie i miejscu. Ponadto zastosowano inną metodę referencyjną pomiaru stężeń PM10 tj. BAM 1020 Met One Instruments zamiast GRIMM EDM 180.

Załadowanie danych weryfikacyjnych.

```{r}
load("dane/data_test.rdata")
```

Podgląd danych:

```{r}
ops_data |> glimpse()
```
Do analizy zostsną wykorzystane dane od `date` do `prec`, połaczone z danymi ramki danych `bam`.

```{r}
bam |> tail(5)
```
Dane będą połączone przy pomocy zmiennej `date` zapobiegając problemowi różnej ilości obserwacji.

Przygotowanie dany:

```{r}
weryfikacja <- ops_data |> select(date:prec)

weryfikacja <- weryfikacja |> 
  left_join(bam, by = "date") |> 
  mutate(grimm_pm10 = bam_pm10) |> 
  select(-bam_pm10)

ops_pm10 <- ops

ops <- ops |> select(-ops_pm10, -pres_sea)

nazwy <- colnames(ops) |> dput()
weryfikacja <- weryfikacja |> 
  select(all_of(nazwy))

colnames(weryfikacja) == colnames(ops)
```
Poniżej wszystkie aktrybuty danych weryfikacyjnych już z podmienioną kolumną `grimm_pm10` na dane pochodzące z czujnika BAM 1020.

Usunieto dodatkowo braki danych znajdujące się w zbiorze.

```{r}
weryfikacja <- weryfikacja |> na.omit()

weryfikacja |> glimpse()
```

# Eskploatacyjna analiza danych

Porównanie wyników pomiarowych stężeń PM_10_ wykonanych przy zastowaniu dwóch podobnych metod pomiarowych:

* **TSI OPS 3330** - metoda optyczna nie uznawana za równoważną do referencyjnej
* **GRIMM EDM180** - metoda optyczna równoważna do referencyjnej (kalibrowana na podstawie danych referencyjnych w lokalizacji wykonywania pomiarów)

```{r}
ops_pm10 |> na.omit() |> 
  ggplot(mapping = aes(x = grimm_pm10, 
                       y = ops_pm10)) + 
  geom_point(shape = 16, alpha = 0.3) +
  geom_abline(slope = c(0.5, 2, 1), 
              col = c( "blue4", "blue4", "red4"), size = 0.8) +
  geom_smooth(method = lm, color = "green4") +
  theme_bw() +
  scale_x_continuous(expand = c(0,0), limits = c(0, 170)) +
  scale_y_continuous(expand = c(0,0), limits = c(0, 170)) + 
  labs(title = "Porównanie metod pomiarowych stężeń PM10", 
       y = "TSI OPS 3330", 
       x = "GRIMM EDM 180") +
  coord_equal()

remove(ops_pm10)
```
Zaobserwowano, że dane z OPS są mocno niedoszacowane względem metody równoważnej do referencyjnej (około 2 krotnie).

## Szereg czasowy danych

```{r}
ops |> 
  ggplot(aes(x = date, y = grimm_pm10)) +
  geom_line(color = "steelblue") +
  theme_bw() +
  labs(title = "Szereg czasowy PM10 GRIMM",
       x = "Data",
       y = "PM10 [µg/m^3^]")
```

W szeregu czasowym można zauważyć znaczną zmienność poziomu stężenia pyłu zawieszonego. Dane wykazują także wyraźny charakter cykliczny, w niektórych dniach obserwuje się zauważalne spadki stężenia w porównaniu z okresami, w których jego poziom jest najwyższy.

## PM10 vs dni tygodnia

Dodanie rozróżnienia w dniach tygodnia

```{r}
ops <- 
  ops |> 
  janitor::clean_names() |> 
  mutate(jday = lubridate::yday(date)) |> 
  mutate(
    wday = lubridate::wday(x = date, abbr = T, label = T),
    hour = lubridate::hour(x = date),
    day_work = case_when(
      wday == "Mon" ~ "week",
      wday == "Tue" ~ "week",
      wday == "Wed" ~ "week",
      wday == "Thu" ~ "week",
      wday == "Fri" ~ "week",
      wday == "Sat" ~ "weekend",
      wday == "Sun" ~ "weekend"
    )
  ) |> 
  mutate(day_work = as.factor(day_work))

weryfikacja <-
  weryfikacja |> 
  janitor::clean_names() |> 
  mutate(jday = lubridate::yday(date)) |> 
  mutate(
    wday = lubridate::wday(x = date, abbr = T, label = T),
    hour = lubridate::hour(x = date),
    day_work = case_when(
      wday == "Mon" ~ "week",
      wday == "Tue" ~ "week",
      wday == "Wed" ~ "week",
      wday == "Thu" ~ "week",
      wday == "Fri" ~ "week",
      wday == "Sat" ~ "weekend",
      wday == "Sun" ~ "weekend"
    )
  ) |> 
  mutate(day_work = as.factor(day_work))
```

Wykres pokazujący średnie wartości stężenia PM10 w danym dniu tygodnia.

```{r}
ops |>
  group_by(wday) |>
  summarise(mean_pm10 = mean(grimm_pm10, na.rm = TRUE)) |>
  ggplot(aes(x = wday, y = mean_pm10, fill = wday)) +
  geom_col(width = 0.7) +
  scale_fill_viridis_d(option = "D") +
  labs(title = "Średnie tygodniowe wartości PM10 (GRIMM)",
      x = "Dzień tygodnia",
      y = "Średnie PM10 GRIMM",
      fill = "Dzień tygodnia") +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold"))
```

Wyraźnie widać spadek stężnież w weekend i środę. Duży wzrost przypada na poniedziałek z tendencją spadkową w kolejne dni.

## Wizualizacja zliczeń w czasie

Przedstawienie danych, które zostaną użyte w modelach ml.

```{r}
ops |> 
  select(date, starts_with("n_0")) |> 
  pivot_longer(cols = starts_with("n_0"),
               names_to = "particle_size",
               values_to = "count") |> 
  mutate(particle_size = factor(particle_size,
                                levels = c("n_0044", "n_0075", "n_0100",
                                           "n_0120", "n_0140", "n_0200",
                                           "n_0250", "n_0500", "n_0750",
                                           "n_1000"))) |> 
  ggplot(aes(x = date, y = particle_size, fill = count)) +
  geom_tile() +
  scale_fill_viridis_c(option = "magma", trans = "log10") +
  labs(title = "Zmienność zliczeń cząstek w czasie (n_0044 – n_1000)",
       x = "Data",
       y = "Rozmiar cząstek",
       fill = "Liczność [log10]") +
  theme_bw()+
  theme(axis.text.y = element_text(size = 9), 
        plot.title = element_text(face = "bold"))
```

Największą ilością charakteryzują się najmniesze cząstki, im większa średnica tym ilość zliczeń jest mniejsza.

## Korelacje między zmiennymi

```{r, fig.width=12, fig.height=12}
ops |> 
  select(grimm_pm10, temp, rh, pres, wd, mws, ws) |> 
  ggpairs() + 
  theme(axis.text = element_text(size = 8),
        strip.text = element_text(size =10))
  
```

Patrząc na korelacje pomiędzy danymi z urządzenia referencyjnego, a warunkami pomiaru można zauważyć dużą korelację prędkości wiatru i stężenia cząstek. Wartości koralacji nie są tak duże by wymagały usunięcia z analizy.

# Podział danych

```{r}
set.seed(423)

data_split <- initial_validation_split(data = ops)

ops_train <- training(data_split)
ops_test <- testing(data_split)
ops_valid <- validation_set(data_split)

save(data_split, ops_train, ops_test, ops_valid, weryfikacja, file = "spliting_ops.Rdata")
```

Dane zostały podzielone na odpowiednie grupy w celu wukonanie modeli uczenia maszynowego.
Jako zbiór weryfikacyjny `weryfikacja`.

# Tworzenie recept

```{r}
base_recipe <- recipe(grimm_pm10 ~ ., data = ops_train) |>
  step_rm(date) |>
  step_mutate(
    hour_sin = sin(2 * pi * hour / 24),
    hour_cos = cos(2 * pi * hour / 24)
  ) |>
  step_rm(hour) |>
  step_mutate(
    wd_sin = sin(wd * pi / 180),
    wd_cos = cos(wd * pi / 180)
  ) |>
  step_rm(wd) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())


recipe_linear <- base_recipe |>
  step_normalize(all_numeric_predictors()) |>
  step_corr(all_numeric_predictors(), threshold = 0.9)

recipe_tree <- base_recipe
```

# Definicja modeli

```{r}
# 1. Linear model
lm_spec <- linear_reg() |>
  set_engine("lm")

# 2. Elastic Net (GLMNet)
glmnet_spec <- linear_reg(
  penalty = tune(),
  mixture = tune()
) |>
  set_engine("glmnet")

# 3. Random Forest
rf_spec <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()
) |>
  set_engine("ranger", importance = "impurity") |>
  set_mode("regression")

# 4. XGBoost
xgb_spec <- boost_tree(
  trees = tune(),
  learn_rate = tune(),
  tree_depth = tune(),
  loss_reduction = tune(),
  min_n = tune()
) |>
  set_engine("xgboost") |>
  set_mode("regression")
```

# Workflowy

```{r}
lm_wf     <- workflow() |> add_model(lm_spec) |> add_recipe(recipe_linear)
glmnet_wf <- workflow() |> add_model(glmnet_spec) |> add_recipe(recipe_linear)
rf_wf     <- workflow() |> add_model(rf_spec) |> add_recipe(recipe_tree)
xgb_wf    <- workflow() |> add_model(xgb_spec) |> add_recipe(recipe_tree)
```

# Walidacja i metryki

```{r}
set.seed(123)
folds <- vfold_cv(ops_train, v = 5)

custom_metrics <- metric_set(rmse, mae, mape, rsq)
```

# Siatki parametrów

```{r}
glmnet_grid <- grid_regular(
  penalty(range = c(-4, 0)),
  mixture(range = c(0, 1)),
  levels = 6
)

rf_grid <- grid_regular(
  mtry(range = c(3, 10)),
  trees(range = c(300, 1000)),
  min_n(range = c(2, 10)),
  levels = 4
)

xgb_grid <- grid_regular(
  trees(range = c(500, 1500)),
  learn_rate(range = c(-3, -1)),
  tree_depth(range = c(2, 8)),
  loss_reduction(),
  min_n(),
  levels = 3
)

```

```{r}
save_file <- "model_results.RData"

if (!file.exists(save_file)) {
  registerDoParallel()
  
  # LM (bez tuningu)
  lm_res <- fit_resamples(
    lm_wf,
    resamples = folds,
    metrics = custom_metrics
  )
  
  # Pozostałe modele z tuningiem
  glmnet_res <- tune_grid(
    glmnet_wf,
    resamples = folds,
    grid = glmnet_grid,
    metrics = custom_metrics
  )
  
  rf_res <- tune_grid(
    rf_wf,
    resamples = folds,
    grid = rf_grid,
    metrics = custom_metrics
  )
  
  xgb_res <- tune_grid(
    xgb_wf,
    resamples = folds,
    grid = xgb_grid,
    metrics = custom_metrics
  )
  
  # Zapis wyników do pliku .RData
  save(lm_res, glmnet_res, rf_res, xgb_res, file = save_file)
  
  cat("Wyniki zapisane do", save_file, "\n")
  
} else {
  cat("Plik", save_file, "już istnieje. Nie zapisano nowych wyników.\n")
  load(save_file)
}

```

# Porównanie wyników

```{r}
results <- bind_rows(
  collect_metrics(lm_res) |> mutate(model = "lm"),
  collect_metrics(glmnet_res) |> mutate(model = "glmnet"),
  collect_metrics(rf_res) |> mutate(model = "rf"),
  collect_metrics(xgb_res) |> mutate(model = "xgb")
)

results_summary <- results |>
  filter(.metric %in% c("rmse", "mae", "mape", "rsq")) |>
  group_by(model, .metric) |>
  summarise(mean = mean(mean), .groups = "drop") |>
  pivot_wider(names_from = .metric, values_from = mean) |>
  arrange(rmse)

results_summary
```

# Wybór najlepszego

```{r}
# Lista modeli i workflow
models <- list(
  lm = lm_wf,
  glmnet = glmnet_wf,
  rf = rf_wf,
  xgb = xgb_wf
)

# Lista wyników resampling / tuning
resamples_list <- list(
  lm = lm_res,       # brak tuningu
  glmnet = glmnet_res,
  rf = rf_res,
  xgb = xgb_res
)

# Lista do przechowywania finalnych workflow
final_workflows <- list()

# Funkcja do finalizacji i last_fit
fit_and_collect <- function(model_name, wf, res) {
  if (model_name %in% c("lm")) {
    # brak tuningu, używamy od razu workflow
    final_wf <- wf
  } else {
    # wybór najlepszego zestawu parametrów wg RMSE
    best_params <- select_best(res, metric = "rmse")
    final_wf <- finalize_workflow(wf, best_params)
  }
  
  # zapisujemy finalny workflow w liście globalnej
  final_workflows[[model_name]] <<- final_wf
  
  # last_fit na podziale danych
  final_fit <- last_fit(final_wf, split = data_split, metrics = custom_metrics)
  
  # zbierz metryki
  metrics <- collect_metrics(final_fit) |>
    mutate(model = model_name)
  
  return(metrics)
}

# Iteracja po wszystkich modelach
all_metrics <- map2_dfr(models, names(models), ~fit_and_collect(.y, .x, resamples_list[[.y]]))

# Tabela szeroka
metrics_table <- all_metrics |>
  select(model, .metric, .estimate) |>
  pivot_wider(
    names_from = .metric,
    values_from = .estimate
  ) |>
  arrange(rmse)

# Wyświetlenie wyników
metrics_table
```

# Weryfikacja na danych zewnętrznych

```{r}
final_fitted <- map(final_workflows, ~fit(.x, data = training(data_split)))
custom_metrics <- metric_set(rmse, mae, rsq, mape)

compute_metrics <- function(model_name, wf) {
  preds <- predict(wf, new_data = weryfikacja) |>
    bind_cols(weryfikacja %>% select(grimm_pm10))
  
  metrics <- custom_metrics(preds, truth = grimm_pm10, estimate = .pred) |>
    mutate(model = model_name)
  
  return(metrics)
}

# iteracja po wszystkich modelach
verification_metrics <- map2_dfr(names(final_fitted), final_fitted, compute_metrics)

# pivot
metrics_table_verif <- verification_metrics |>
  select(model, .metric, .estimate) |>
  pivot_wider(names_from = .metric, values_from = .estimate) |>
  arrange(rmse)

metrics_table_verif
```